{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.FloatTensor(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1483e+35,  4.5629e-41],\n",
       "        [ 1.2287e+05,  3.0698e-41],\n",
       "        [ 4.4842e-44,  0.0000e+00]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [3., 2., 1.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor([[1, 2, 3], [3, 2, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.zeros(shape= (3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.tensor(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.zeros(shape= (3, 2), dtype= np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.zeros(shape= (3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(n, dtype= torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalar tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.FloatTensor([[1, 2, 3], [3, 2, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 3.],\n",
       "        [2., 2.],\n",
       "        [3., 1.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transpose\n",
    "a.t()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 3.],\n",
       "        [2., 2.],\n",
       "        [3., 1.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.FloatTensor([[4, 5, 6], [6, 5, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2., 3.],\n",
       "         [3., 2., 1.]],\n",
       "\n",
       "        [[4., 5., 6.],\n",
       "         [6., 5., 4.]]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = torch.stack((a, b))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [3., 2., 1.],\n",
       "        [4., 5., 6.],\n",
       "        [6., 5., 4.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.cat((a, b))\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.FloatTensor([2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 3.])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (35) : CUDA driver version is insufficient for CUDA runtime version at /pytorch/aten/src/THC/THCGeneral.cpp:74",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-d9c905c3a69e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mca\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (35) : CUDA driver version is insufficient for CUDA runtime version at /pytorch/aten/src/THC/THCGeneral.cpp:74"
     ]
    }
   ],
   "source": [
    "ca = a.cuda(); ca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors & Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = torch.tensor([1.0, 1.0], requires_grad= True)\n",
    "v2 = torch.tensor([2.0, 2.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_sum = v1 + v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_res = (v_sum*2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.is_leaf, v2.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_sum.is_leaf, v_res.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_sum.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_res.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2.])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_res.backward()\n",
    "v1.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN building Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = nn.Linear(2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.FloatTensor([1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.1893,  0.6032, -0.6738, -1.0736,  0.9869], grad_fn=<ThAddBackward>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.5080,  0.5713],\n",
       "         [-0.0572,  0.6164],\n",
       "         [-0.6636,  0.1897],\n",
       "         [-0.0598, -0.6657],\n",
       "         [ 0.2795,  0.6028]], requires_grad=True), Parameter containing:\n",
       " tensor([ 0.5548, -0.5725, -0.3895,  0.3175, -0.4981], requires_grad=True)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p for p in l.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight', tensor([[-0.5080,  0.5713],\n",
       "                      [-0.0572,  0.6164],\n",
       "                      [-0.6636,  0.1897],\n",
       "                      [-0.0598, -0.6657],\n",
       "                      [ 0.2795,  0.6028]])),\n",
       "             ('bias', tensor([ 0.5548, -0.5725, -0.3895,  0.3175, -0.4981]))])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = nn.Sequential(\n",
    "    nn.Linear(2,5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5, 20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10),\n",
    "    nn.Dropout(p= 0.3),\n",
    "    nn.Softmax(dim= 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=5, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=5, out_features=20, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=20, out_features=10, bias=True)\n",
       "  (5): Dropout(p=0.3)\n",
       "  (6): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1110, 0.1110, 0.0818, 0.0842, 0.1092, 0.1110, 0.1110, 0.1062, 0.1110,\n",
       "         0.0634]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s(torch.FloatTensor([[1, 2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurModule(nn.Module):\n",
    "    def __init__(self, num_inputs, num_classes, dropout_prob= 0.3):\n",
    "        super(OurModule, self).__init__()\n",
    "        self.pipe= nn.Sequential(\n",
    "                    nn.Linear(num_inputs,5),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(5, 20),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(20, num_classes),\n",
    "                    nn.Dropout(p= dropout_prob),\n",
    "                    nn.Softmax(dim= 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.pipe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "net= OurModule(num_inputs= 30, num_classes= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.FloatTensor([np.random.random(30)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "out= net(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OurModule(\n",
       "  (pipe): Sequential(\n",
       "    (0): Linear(in_features=30, out_features=5, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=5, out_features=20, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=20, out_features=2, bias=True)\n",
       "    (5): Dropout(p=0.3)\n",
       "    (6): Softmax()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4771, 0.5229]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.1066,  0.1142,  0.0978, -0.0801,  0.0075,  0.0044, -0.1119,  0.1644,\n",
       "          -0.0205,  0.0149, -0.0232,  0.0602,  0.0402, -0.0785, -0.0785, -0.1303,\n",
       "          -0.0515, -0.0331,  0.0963, -0.0727,  0.1258,  0.0586,  0.0029,  0.0395,\n",
       "           0.0967, -0.1170,  0.0999, -0.0421,  0.1532, -0.0648],\n",
       "         [ 0.0264,  0.0931, -0.1604, -0.0483, -0.0499,  0.0640, -0.1147,  0.0847,\n",
       "          -0.0567, -0.0811, -0.0304, -0.1198,  0.1481, -0.0549,  0.0479, -0.0590,\n",
       "           0.0546, -0.0666, -0.0252,  0.0890, -0.0263,  0.1436, -0.1154, -0.1020,\n",
       "           0.0377,  0.1539, -0.1371, -0.1420,  0.1155, -0.0710],\n",
       "         [-0.0183, -0.1143, -0.0693, -0.1798,  0.0648, -0.1263,  0.1080,  0.1766,\n",
       "          -0.0066, -0.0918,  0.1046,  0.0346,  0.0062, -0.0474,  0.0837,  0.0667,\n",
       "           0.0942, -0.1509, -0.0230, -0.1542,  0.0042, -0.0084, -0.0275, -0.1309,\n",
       "           0.1144,  0.0773, -0.0705, -0.1124,  0.0975,  0.1761],\n",
       "         [-0.1665, -0.1319,  0.0694,  0.1410, -0.0461,  0.0925,  0.0983, -0.1758,\n",
       "           0.0357,  0.1183,  0.0107, -0.0494,  0.0751,  0.0100,  0.0160,  0.0846,\n",
       "          -0.0151,  0.1170,  0.1693,  0.1611, -0.0799, -0.0463, -0.1094,  0.1087,\n",
       "          -0.1706, -0.1442,  0.0167, -0.0201, -0.1286, -0.0491],\n",
       "         [-0.1699,  0.0890,  0.1825, -0.1350, -0.1213,  0.0676,  0.1521,  0.1659,\n",
       "          -0.1404, -0.1173, -0.1158,  0.1490, -0.1064, -0.1373,  0.0998,  0.0340,\n",
       "           0.0478,  0.1338, -0.1090,  0.1229, -0.0907,  0.1560,  0.0049, -0.0996,\n",
       "           0.1725,  0.1040, -0.0969,  0.0978, -0.0395, -0.1528]],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([ 0.1552, -0.0837, -0.0037,  0.1281, -0.0026], requires_grad=True), Parameter containing:\n",
       " tensor([[ 0.1302,  0.2835,  0.1711,  0.3031, -0.2894],\n",
       "         [-0.3122,  0.0972,  0.1353, -0.2936,  0.0334],\n",
       "         [-0.3503,  0.0108, -0.1455,  0.3469,  0.3489],\n",
       "         [ 0.3692, -0.1404,  0.1467,  0.1487, -0.4123],\n",
       "         [-0.2844, -0.4464,  0.3813,  0.3580, -0.0198],\n",
       "         [-0.3395,  0.2879, -0.1271, -0.4344,  0.1925],\n",
       "         [-0.0705,  0.2903, -0.0345,  0.1518,  0.2589],\n",
       "         [-0.2188, -0.2353,  0.0397,  0.2998,  0.0577],\n",
       "         [ 0.3514,  0.3535,  0.3171, -0.3317, -0.3085],\n",
       "         [ 0.0763,  0.2365,  0.4321,  0.2878, -0.3974],\n",
       "         [ 0.1209, -0.1237, -0.4432, -0.3677, -0.1671],\n",
       "         [ 0.4182, -0.1286, -0.1782,  0.3868,  0.1513],\n",
       "         [ 0.1412, -0.1514,  0.1512, -0.3728, -0.0206],\n",
       "         [ 0.2432,  0.0864, -0.2949,  0.2711, -0.1362],\n",
       "         [ 0.3779,  0.0106,  0.2371,  0.0561,  0.0303],\n",
       "         [ 0.2726, -0.0583, -0.2771,  0.1459, -0.1798],\n",
       "         [-0.0272, -0.0821,  0.2866, -0.1552,  0.0699],\n",
       "         [-0.2992, -0.1984,  0.2251,  0.1261, -0.0006],\n",
       "         [ 0.2223, -0.0288, -0.2847,  0.4378,  0.4101],\n",
       "         [-0.0340,  0.4292,  0.3300,  0.4403, -0.1811]], requires_grad=True), Parameter containing:\n",
       " tensor([-0.3940, -0.0368, -0.3708,  0.2859, -0.0995, -0.0828,  0.0889, -0.4221,\n",
       "         -0.1545,  0.0330, -0.3004,  0.1091,  0.3640, -0.1371, -0.1320, -0.1232,\n",
       "          0.4373, -0.4221,  0.3983, -0.0486], requires_grad=True), Parameter containing:\n",
       " tensor([[ 0.1797, -0.1855, -0.1879, -0.1903, -0.2069, -0.0982,  0.0065,  0.0556,\n",
       "           0.1748, -0.1679,  0.0355,  0.0278,  0.1886, -0.1889, -0.1591, -0.2103,\n",
       "           0.1558, -0.0611, -0.1846,  0.1469],\n",
       "         [ 0.2121,  0.1493,  0.2232, -0.1155, -0.0611,  0.1375, -0.1251, -0.0028,\n",
       "          -0.0097, -0.1248, -0.1181,  0.0424,  0.1071, -0.1951, -0.1508, -0.1717,\n",
       "           0.0459,  0.0074,  0.2018,  0.1549]], requires_grad=True), Parameter containing:\n",
       " tensor([-0.1592, -0.2086], requires_grad=True)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p for p in net.parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss functions and optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples = 200, n_features= 30, centers= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(net(torch.tensor(X_test, dtype= torch.float32))) == torch.tensor(y_test, dtype= torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_batches(features, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Get a range of batches. Use as argument of a for loop like you would normally use\n",
    "    the range() function.\n",
    "    \"\"\"\n",
    "    idx = np.arange(features.shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    for b_i in np.arange(0, features.shape[0] , batch_size):\n",
    "        batch_indices = np.sort(idx[b_i:b_i + batch_size])\n",
    "        X_batch = features[batch_indices]\n",
    "        y_batch = labels[batch_indices]\n",
    "\n",
    "            #if add_dummy_dimension:\n",
    "            #    X_batch = np.expand_dims(X_batch, axis=-1)\n",
    "\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adagrad(net.parameters(), lr= 0.01)\n",
    "\n",
    "for e in range(100):\n",
    "    for batch_samples, batch_labels in iterate_batches(X_train, y_train, 10):\n",
    "        batch_samples_t = torch.tensor(batch_samples, dtype=torch.float32)\n",
    "        batch_labels_t = torch.tensor(batch_labels, dtype= torch.long)\n",
    "        optimizer.zero_grad()\n",
    "        out_t = net(batch_samples_t)\n",
    "        #print(\"out_t:\", out_t)\n",
    "        #print(\"ba:\", batch_labels_t)\n",
    "        loss = criterion(out_t, batch_labels_t)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "        0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1],\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(net(torch.tensor(X_test, dtype= torch.float32))) == torch.tensor(y_test, dtype= torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0977,  0.0524,  0.0439, -0.0218, -0.0445, -0.0513, -0.1715,  0.0963,\n",
       "          -0.0799, -0.0410,  0.0173,  0.1192,  0.0652, -0.1274, -0.0178, -0.0717,\n",
       "           0.0086, -0.0538,  0.1582, -0.1306,  0.0972,  0.0124,  0.0626,  0.0984,\n",
       "           0.1553, -0.0596,  0.1496, -0.0994,  0.2018, -0.0081],\n",
       "         [-0.0791,  0.0261, -0.2296,  0.0174, -0.1213, -0.0062, -0.1815,  0.0118,\n",
       "          -0.1244, -0.1491,  0.0361, -0.0483,  0.1990, -0.1184,  0.1196,  0.0112,\n",
       "           0.1158, -0.1343,  0.0390,  0.0214, -0.0918,  0.0732, -0.0490, -0.0347,\n",
       "           0.1059,  0.2210, -0.1055, -0.2077,  0.1679, -0.0007],\n",
       "         [-0.0116, -0.1764, -0.1314, -0.1325,  0.0073, -0.1878,  0.0401,  0.1064,\n",
       "          -0.0722, -0.1512,  0.1476,  0.1004,  0.0393, -0.0971,  0.1408,  0.1278,\n",
       "           0.1450, -0.1773,  0.0408, -0.2209, -0.0361, -0.0604,  0.0342, -0.0666,\n",
       "           0.1717,  0.1268, -0.0096, -0.1692,  0.1433,  0.2436],\n",
       "         [-0.2525, -0.0496, -0.0198,  0.0548, -0.1262,  0.1736,  0.1730, -0.2326,\n",
       "           0.1219,  0.0284,  0.1003, -0.1357, -0.0123, -0.0772, -0.0721,  0.0007,\n",
       "          -0.1040,  0.0312,  0.0810,  0.2460,  0.0062, -0.1294, -0.1916,  0.0283,\n",
       "          -0.2576, -0.2317, -0.0189, -0.0947, -0.2129, -0.0719],\n",
       "         [-0.1699,  0.0890,  0.1825, -0.1350, -0.1213,  0.0676,  0.1521,  0.1659,\n",
       "          -0.1404, -0.1173, -0.1158,  0.1490, -0.1064, -0.1373,  0.0998,  0.0340,\n",
       "           0.0478,  0.1338, -0.1090,  0.1229, -0.0907,  0.1560,  0.0049, -0.0996,\n",
       "           0.1725,  0.1040, -0.0969,  0.0978, -0.0395, -0.1528]],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([ 0.1967, -0.0168,  0.0445,  0.2149, -0.0026], requires_grad=True), Parameter containing:\n",
       " tensor([[ 0.1019,  0.2207,  0.1135,  0.3489, -0.2894],\n",
       "         [-0.3443,  0.0657,  0.1190, -0.2936,  0.0334],\n",
       "         [-0.3141,  0.0108, -0.1250,  0.4687,  0.3489],\n",
       "         [ 0.3989, -0.1172,  0.1635,  0.0971, -0.4123],\n",
       "         [-0.2900, -0.4726,  0.3630,  0.4314, -0.0198],\n",
       "         [-0.3395,  0.2879, -0.1271, -0.4344,  0.1925],\n",
       "         [-0.0066,  0.4084,  0.0554,  0.0430,  0.2589],\n",
       "         [-0.2188, -0.2353,  0.0207,  0.4381,  0.0577],\n",
       "         [ 0.4574,  0.4666,  0.3897, -0.3417, -0.3085],\n",
       "         [ 0.1256,  0.2832,  0.4770,  0.2212, -0.3974],\n",
       "         [ 0.1209, -0.1237, -0.4432, -0.3677, -0.1671],\n",
       "         [ 0.4232, -0.1594, -0.2041,  0.5171,  0.1513],\n",
       "         [ 0.2198, -0.0699,  0.2099, -0.3628, -0.0206],\n",
       "         [ 0.2367,  0.0864, -0.3150,  0.2498, -0.1362],\n",
       "         [ 0.4480,  0.1152,  0.3196,  0.0093,  0.0303],\n",
       "         [ 0.2696, -0.0583, -0.2761,  0.1405, -0.1798],\n",
       "         [ 0.0444,  0.0224,  0.3552, -0.1723,  0.0699],\n",
       "         [-0.3060, -0.1984,  0.2140,  0.3120, -0.0006],\n",
       "         [ 0.2478, -0.0388, -0.2714,  0.5466,  0.4101],\n",
       "         [-0.0429,  0.4187,  0.2966,  0.4741, -0.1811]], requires_grad=True), Parameter containing:\n",
       " tensor([-0.3815, -0.0537, -0.2838,  0.2470, -0.0999, -0.0828,  0.0597, -0.3226,\n",
       "         -0.1024, -0.0074, -0.3004,  0.2045,  0.4083, -0.1533, -0.1264, -0.1276,\n",
       "          0.4925, -0.4010,  0.4669, -0.0341], requires_grad=True), Parameter containing:\n",
       " tensor([[ 0.2183, -0.1745, -0.3295, -0.1315, -0.2331, -0.0982,  0.0656, -0.0984,\n",
       "           0.2527, -0.1113,  0.0355, -0.0550,  0.2459, -0.2677, -0.0753, -0.2777,\n",
       "           0.2090, -0.0854, -0.2704,  0.1857],\n",
       "         [ 0.1947,  0.1383,  0.3497, -0.1679, -0.0096,  0.1375, -0.1709,  0.1338,\n",
       "          -0.1031, -0.1917, -0.1181,  0.1286,  0.0348, -0.1129, -0.2491, -0.0986,\n",
       "          -0.0228,  0.0602,  0.2905,  0.1246]], requires_grad=True), Parameter containing:\n",
       " tensor([-0.1349, -0.2148], requires_grad=True)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p for p in net.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
